{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazypredict: Запуск усіх алгоритмів `sklearn` одним рядком коду\n",
    "\n",
    "Як його використовувати (і чому не варто)\n",
    "\n",
    "https://pub.towardsai.net/lazypredict-run-all-sklearn-algorithms-with-a-line-of-code-29d73d82499c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Спочатку ми імпортуємо набір даних \"Діабет\".\n",
    "\n",
    "Для кожного з $n = 442$ пацієнтів з діабетом було отримано десять базових змінних: вік, стать, індекс маси тіла, середній кров'яний тиск та шість показників сироватки крові, а також відповідь, що нас цікавить, - кількісний показник прогресування хвороби через рік після базового рівня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Diabetes Dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "print(diabetes.DESCR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Далі ми перетасуємо набір даних, щоб розділити їх на набори тренувань і тестів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "X, y = shuffle(diabetes.data, diabetes.target, random_state=13)\n",
    "\n",
    "# Cast the numerical values into a numpy float.\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "# Split the dataset into 90% and 10%.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Далі ініціалізуємо об'єкт LazyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the Lazypredict library and fit multiple regression libraries\n",
    "# for the same dataset\n",
    "reg = LazyRegressor(verbose=0,\n",
    "                    ignore_warnings=False,\n",
    "                    custom_metric=None,\n",
    "                    predictions=False,\n",
    "                    random_state=13,\n",
    "                    )\n",
    "\n",
    "# Parameters\n",
    "# ----------\n",
    "# verbose : int, optional (default=0)\n",
    "#       For the liblinear and lbfgs solvers set verbose to any positive\n",
    "#       number for verbosity.\n",
    "# ignore_warnings : bool, optional (default=True)\n",
    "#       When set to True, the warning related to algorigms that are not able\n",
    "#       to run are ignored.\n",
    "# custom_metric : function, optional (default=None)\n",
    "#       When function is provided, models are evaluated based on the custom\n",
    "#       evaluation metric provided.\n",
    "# prediction : bool, optional (default=False)\n",
    "#       When set to True, the predictions of all the models models are\n",
    "#       returned as dataframe.\n",
    "# regressors : list, optional (default=\"all\")\n",
    "#       When function is provided, trains the chosen regressor(s).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тепер ми поєднаємо алгоритми множинної регресії з бібліотекою `lazypredict`. Цей крок зайняв 3 секунди.\n",
    "\n",
    "По суті, метод підгонки робить наступне:\n",
    "\n",
    "1. Розділіть всі об'єкти на три категорії: числові (об'єкти, які є числами) або категоріальні (об'єкти, які є текстом). \n",
    "2. Далі розділіть категоріальні ознаки на дві: \"високі\" категоріальні ознаки (які мають більше унікальних значень, ніж загальна кількість ознак) і \"низькі\" категоріальні ознаки (які мають менше унікальних значень, ніж загальна кількість ознак).\n",
    "3. Потім кожна ознака попередньо обробляється таким чином:\n",
    "\n",
    "- Числові ознаки: Замінимо відсутні значення середнім значенням, а потім стандартизуємо ознаку (вилучимо середнє значення та поділити на дисперсію) \n",
    "- \"Високі\" категоріальні ознаки: Пропущені значення замінюються значенням \"missing\", а потім виконується однократне кодування. \n",
    "- \"Низькі\" категоріальні ознаки: Присвоїмо відсутнім значенням значення \"missing\", а потім виконати порядкове кодування (перетворити кожне унікальне значення рядка на ціле число). У прикладі зі стовпчиком \"Стать\" - \"Чоловік\" кодується як 0, а \"Жінка\" - як 1.\n",
    "- Підберемо навчальний набір даних для кожного алгоритму. - \n",
    "- Протестуємо кожен алгоритм на тестовому наборі даних. За замовчуванням, метрики наступні: приведений $R^2$, $R^2$, середньоквадратична помилка (MSE) та витрачений час."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:05<00:00,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 640\n",
      "[LightGBM] [Info] Number of data points in the train set: 397, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 151.722922\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "model_dictionary = reg.provide_models(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>54.39</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>54.46</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>54.46</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.51</td>\n",
       "      <td>54.54</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.51</td>\n",
       "      <td>54.59</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.51</td>\n",
       "      <td>54.79</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.51</td>\n",
       "      <td>54.83</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.51</td>\n",
       "      <td>54.91</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.51</td>\n",
       "      <td>54.91</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.51</td>\n",
       "      <td>54.94</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.51</td>\n",
       "      <td>54.96</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.51</td>\n",
       "      <td>54.96</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.51</td>\n",
       "      <td>54.96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.50</td>\n",
       "      <td>55.09</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.50</td>\n",
       "      <td>55.20</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.50</td>\n",
       "      <td>55.24</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.49</td>\n",
       "      <td>55.93</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.49</td>\n",
       "      <td>56.08</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.48</td>\n",
       "      <td>56.42</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonRegressor</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>56.61</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>56.61</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>56.68</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>57.49</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>57.57</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.45</td>\n",
       "      <td>57.87</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.45</td>\n",
       "      <td>58.15</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.45</td>\n",
       "      <td>58.18</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.44</td>\n",
       "      <td>58.71</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.42</td>\n",
       "      <td>59.44</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.42</td>\n",
       "      <td>59.81</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GammaRegressor</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.40</td>\n",
       "      <td>60.61</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.34</td>\n",
       "      <td>63.55</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>64.66</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.18</td>\n",
       "      <td>71.06</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>72.04</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>78.37</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileRegressor</th>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>79.84</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>82.44</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>89.16</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>-0.77</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>91.51</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>-2.19</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>122.91</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>-5.04</td>\n",
       "      <td>-3.67</td>\n",
       "      <td>169.06</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Adjusted R-Squared  R-Squared   RMSE  \\\n",
       "Model                                                                 \n",
       "OrthogonalMatchingPursuitCV                  0.37       0.52  54.39   \n",
       "Lasso                                        0.37       0.52  54.46   \n",
       "LassoLars                                    0.37       0.52  54.46   \n",
       "LarsCV                                       0.37       0.51  54.54   \n",
       "LassoCV                                      0.37       0.51  54.59   \n",
       "SGDRegressor                                 0.37       0.51  54.79   \n",
       "LassoLarsIC                                  0.36       0.51  54.83   \n",
       "RidgeCV                                      0.36       0.51  54.91   \n",
       "Ridge                                        0.36       0.51  54.91   \n",
       "BayesianRidge                                0.36       0.51  54.94   \n",
       "LassoLarsCV                                  0.36       0.51  54.96   \n",
       "TransformedTargetRegressor                   0.36       0.51  54.96   \n",
       "LinearRegression                             0.36       0.51  54.96   \n",
       "Lars                                         0.36       0.50  55.09   \n",
       "ElasticNetCV                                 0.36       0.50  55.20   \n",
       "HuberRegressor                               0.36       0.50  55.24   \n",
       "LGBMRegressor                                0.34       0.49  55.93   \n",
       "HistGradientBoostingRegressor                0.34       0.49  56.08   \n",
       "RandomForestRegressor                        0.33       0.48  56.42   \n",
       "PoissonRegressor                             0.32       0.48  56.61   \n",
       "ExtraTreesRegressor                          0.32       0.48  56.61   \n",
       "PassiveAggressiveRegressor                   0.32       0.48  56.68   \n",
       "ElasticNet                                   0.30       0.46  57.49   \n",
       "KNeighborsRegressor                          0.30       0.46  57.57   \n",
       "OrthogonalMatchingPursuit                    0.29       0.45  57.87   \n",
       "AdaBoostRegressor                            0.29       0.45  58.15   \n",
       "XGBRegressor                                 0.28       0.45  58.18   \n",
       "BaggingRegressor                             0.27       0.44  58.71   \n",
       "GradientBoostingRegressor                    0.25       0.42  59.44   \n",
       "TweedieRegressor                             0.24       0.42  59.81   \n",
       "GammaRegressor                               0.22       0.40  60.61   \n",
       "RANSACRegressor                              0.15       0.34  63.55   \n",
       "LinearSVR                                    0.12       0.32  64.66   \n",
       "NuSVR                                       -0.07       0.18  71.06   \n",
       "SVR                                         -0.10       0.15  72.04   \n",
       "DummyRegressor                              -0.30      -0.00  78.37   \n",
       "QuantileRegressor                           -0.35      -0.04  79.84   \n",
       "ExtraTreeRegressor                          -0.44      -0.11  82.44   \n",
       "DecisionTreeRegressor                       -0.68      -0.30  89.16   \n",
       "GaussianProcessRegressor                    -0.77      -0.37  91.51   \n",
       "MLPRegressor                                -2.19      -1.47 122.91   \n",
       "KernelRidge                                 -5.04      -3.67 169.06   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "OrthogonalMatchingPursuitCV          0.02  \n",
       "Lasso                                0.02  \n",
       "LassoLars                            0.02  \n",
       "LarsCV                               0.03  \n",
       "LassoCV                              0.08  \n",
       "SGDRegressor                         0.01  \n",
       "LassoLarsIC                          0.02  \n",
       "RidgeCV                              0.01  \n",
       "Ridge                                0.01  \n",
       "BayesianRidge                        0.02  \n",
       "LassoLarsCV                          0.03  \n",
       "TransformedTargetRegressor           0.01  \n",
       "LinearRegression                     0.00  \n",
       "Lars                                 0.02  \n",
       "ElasticNetCV                         0.16  \n",
       "HuberRegressor                       0.03  \n",
       "LGBMRegressor                        0.11  \n",
       "HistGradientBoostingRegressor        0.32  \n",
       "RandomForestRegressor                0.64  \n",
       "PoissonRegressor                     0.02  \n",
       "ExtraTreesRegressor                  0.41  \n",
       "PassiveAggressiveRegressor           0.02  \n",
       "ElasticNet                           0.02  \n",
       "KNeighborsRegressor                  0.02  \n",
       "OrthogonalMatchingPursuit            0.02  \n",
       "AdaBoostRegressor                    0.06  \n",
       "XGBRegressor                         0.13  \n",
       "BaggingRegressor                     0.11  \n",
       "GradientBoostingRegressor            0.20  \n",
       "TweedieRegressor                     0.01  \n",
       "GammaRegressor                       0.02  \n",
       "RANSACRegressor                      0.15  \n",
       "LinearSVR                            0.02  \n",
       "NuSVR                                0.02  \n",
       "SVR                                  0.02  \n",
       "DummyRegressor                       0.01  \n",
       "QuantileRegressor                    2.40  \n",
       "ExtraTreeRegressor                   0.06  \n",
       "DecisionTreeRegressor                0.03  \n",
       "GaussianProcessRegressor             0.05  \n",
       "MLPRegressor                         0.37  \n",
       "KernelRidge                          0.02  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чи рекомендую я `lazypredict`?\n",
    "\n",
    "Якщо ви встановите його, `lazypredict` дуже простий у використанні. Його синтаксис дуже близький до `scikit-learn`, що робить криву навчання дуже пологою.\n",
    "\n",
    "Але у нього є кілька критичних недоліків.\n",
    "\n",
    "1. __Складне встановлення__: Багато хто повідомляв про труднощі при встановленні бібліотек, тому що розробники не додали файл requirements.txt, який документує необхідні залежності.\n",
    "   \n",
    "2. __Обмежена документація__: Мені довелося прочісувати вихідний код, щоб дізнатися, як працює препроцесор. Це не ідеально. Я також не знаю гіперпараметрів, які використовуються для виконання кожного із завдань класифікації та регресії. \n",
    "   \n",
    "3. __Обмежена можливість налаштування__: Я все ще не знайшов способів налаштувати кроки попередньої обробки. \n",
    "   \n",
    "4. Незрозуміло, як використовувати модель після `lazypredict`: Після того, як ви закінчите роботу з бібліотекою `lazypredict`, ви в ідеалі захочете вибрати найкращий алгоритм. `Lazypredict` не робить це простим, оскільки у вас немає простого способу експортувати найкращий алгоритм."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
